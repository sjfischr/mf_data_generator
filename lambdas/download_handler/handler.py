"""Download Handler Lambda — returns presigned S3 URLs for completed jobs."""

import json
import logging

from lambdas.shared import s3_utils

logger = logging.getLogger(__name__)


def handler(event, context):
    job_id = event.get("pathParameters", {}).get("job_id", "")

    if not job_id:
        return {
            "statusCode": 400,
            "headers": {"Content-Type": "application/json", "Access-Control-Allow-Origin": "*"},
            "body": json.dumps({"error": "Missing job_id"}),
        }

    try:
        # Check if download URLs were already generated by the assembler
        urls = s3_utils.read_json(job_id, "outputs/download_urls.json")

        return {
            "statusCode": 200,
            "headers": {"Content-Type": "application/json", "Access-Control-Allow-Origin": "*"},
            "body": json.dumps({
                "status": "ready",
                "job_id": job_id,
                "urls": urls,
            }),
        }

    except Exception:
        # URLs not yet available — generate fresh presigned URLs if files exist
        try:
            output_files = s3_utils.list_files(job_id, "outputs/")
            if not output_files:
                return {
                    "statusCode": 404,
                    "headers": {"Content-Type": "application/json", "Access-Control-Allow-Origin": "*"},
                    "body": json.dumps({
                        "status": "not_ready",
                        "job_id": job_id,
                        "message": "Job outputs not yet available",
                    }),
                }

            urls = {}
            for key in output_files:
                filename = key.split("/")[-1]
                if filename.endswith(".docx"):
                    urls["appraisal"] = s3_utils.generate_presigned_url(job_id, f"outputs/{filename}")
                elif filename == "rent_roll.xlsx":
                    urls["rent_roll"] = s3_utils.generate_presigned_url(job_id, f"outputs/{filename}")
                elif filename.startswith("t12_"):
                    urls.setdefault("t12_files", []).append(
                        s3_utils.generate_presigned_url(job_id, f"outputs/{filename}")
                    )
                elif filename.endswith(".zip"):
                    urls["complete_package"] = s3_utils.generate_presigned_url(job_id, f"outputs/{filename}")

            return {
                "statusCode": 200,
                "headers": {"Content-Type": "application/json", "Access-Control-Allow-Origin": "*"},
                "body": json.dumps({
                    "status": "ready",
                    "job_id": job_id,
                    "urls": urls,
                }),
            }

        except Exception as e:
            logger.error("Error generating download links for job %s: %s", job_id, e)
            return {
                "statusCode": 500,
                "headers": {"Content-Type": "application/json", "Access-Control-Allow-Origin": "*"},
                "body": json.dumps({"error": str(e)}),
            }
